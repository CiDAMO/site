<!doctype html><html lang=pt-br><head>
<meta charset=utf-8>
<title>Reconhecimento de Caracteres Matemáticos utilizando Deep Learning</title>
<meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1">
<meta name=description content="Este blogpost faz referência ao 3º desafio do curso de Machine Learning proposto dentro do grupo CiDAMO da UFPR aos seus mais novos membros e tem como objetivo descrever o processo de solução encontrada pela equipe no tema reconhecimento de caracteres matemáticos.">
<meta name=author content="Themefisher">
<meta name=generator content="Hugo 0.91.2">
<meta property="og:image" content="http://cidamo.netlify.app/images/blog/reconhecimento-caracteres/capa.jpg">
<meta name=twitter:image content="http://cidamo.netlify.app/images/blog/reconhecimento-caracteres/capa.jpg">
<meta name=twitter:card content="summary">
<meta property="og:image:width" content="1080">
<meta property="og:image:height" content="1080">
<meta property="og:image:type" content="image/jpeg">
<meta name=twitter:title content="Reconhecimento de Caracteres Matemáticos utilizando Deep Learning">
<meta name=twitter:description content="Este blogpost faz referência ao 3º desafio do curso de Machine Learning proposto dentro do grupo CiDAMO da UFPR aos seus mais novos membros e tem como objetivo descrever o processo de solução encontrada pela equipe no tema reconhecimento de caracteres matemáticos.">
<meta property="og:title" content="Reconhecimento de Caracteres Matemáticos utilizando Deep Learning">
<meta property="og:description" content="Este blogpost faz referência ao 3º desafio do curso de Machine Learning proposto dentro do grupo CiDAMO da UFPR aos seus mais novos membros e tem como objetivo descrever o processo de solução encontrada pela equipe no tema reconhecimento de caracteres matemáticos.">
<meta property="og:type" content="article">
<meta property="og:url" content="http://cidamo.netlify.app/blog/2020-06-30-reconhecimento-de-caracteres/"><meta property="article:section" content="blog">
<meta property="article:published_time" content="2020-06-30T00:00:00+00:00">
<meta property="article:modified_time" content="2020-06-30T00:00:00+00:00">
<link rel=stylesheet href=/plugins/bootstrap/css/bootstrap.min.css media=screen>
<link rel=stylesheet href=/plugins/ionicons/css/ionicons.min.css>
<link rel=stylesheet href=/plugins/magnific-popup/magnific-popup.min.css>
<link rel=stylesheet href=/plugins/slick/slick.css>
<link rel=stylesheet href=/scss/bundled.min.css media=screen>
<link rel="shortcut icon" href=/images/favicon.png type=image/x-icon>
<link rel=icon href=/images/favicon.png type=image/x-icon>
</head>
<body>
<div class=preloader>
</div>
<header class=navigation>
<div class=container-fluid>
<div class=row>
<div class=col-md-12>
<nav class=navbar>
<div class=navbar-header>
<button type=button class="navbar-toggle collapsed" data-toggle=collapse data-target=#navigation>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=/>
<img src=/images/logo.png alt=CiDAMO width=150px class=img-responsive>
</a>
</div>
<div class="collapse navbar-collapse" id=navigation>
<ul class="nav navbar-nav navbar-right">
<li><a href=/>Home</a></li><li><a href=/sobre/>Sobre</a></li><li><a href=/equipe/>Equipe</a></li><li><a href=/eventos/>Eventos</a></li><li><a href=/blog/ class=current-parent>Blog</a></li>
</ul>
</div>
</nav>
</div>
</div>
</div>
</header>
<section class="page-title bg-2" style=background-image:url(/images/blog/reconhecimento-caracteres/capa.jpg)>
<div class=container>
<div class=row>
<div class=col-md-12>
<div class=block>
<h1>Reconhecimento de Caracteres Matemáticos utilizando Deep Learning</h1>
<p></p>
</div>
</div>
</div>
</div>
</section>
<section class=page-wrapper>
<div class=container>
<div class=row>
<div class=col-md-8>
<div class="post post-single">
<h2 class=post-title>Reconhecimento de Caracteres Matemáticos utilizando Deep Learning</h2>
<div class=post-meta>
<ul>
<li><i class=ion-calendar></i> June 30, 2020</li>
<li><i class=ion-android-people></i>
Postado por
<a class=text-primary href=/author/albert-favero>Albert Favero</a>, <a class=text-primary href=/author/lucas-akio>Lucas Akio</a>, <a class=text-primary href=/author/pedro-vianna>Pedro Vianna</a>, <a class=text-primary href=/author/rog%C3%A9rio-mainardes>Rogério Mainardes</a>
</li>
<li><i class=ion-pricetags></i>
<a href=/tags/classifica%c3%a7%c3%a3o>Classificação</a>
</li>
</ul>
</div>
<div class=post-thumb>
<img class=img-responsive src=/images/blog/reconhecimento-caracteres/capa.jpg alt="Reconhecimento de Caracteres Matemáticos utilizando Deep Learning">
</div>
<div class="post-content post-excerpt">
<p>Este blogpost faz referência ao 3º desafio do curso de <em>Machine Learning</em> proposto dentro do grupo <a href=https://cidamo.com.br/ title=CiDAMO>CiDAMO</a> da UFPR aos seus mais novos membros e tem como objetivo descrever o processo de solução encontrada pela equipe no tema reconhecimento de caracteres matemáticos. A turma foi dividida em 5 equipes e cada uma escolheu o assunto que mais lhe interessava explorar.</p>
<p>Faz parte do escopo dessa postagem, também, citar os projetos anteriores que foram utilizadas como referências, os <em>datasets</em> empregados, as dificuldades encontradas, os resultados finais, além dos próximos passos e objetivos.</p>
<h3 id=contextualização>Contextualização</h3>
<p>O crescimento exponencial de dados que vemos nos últimos anos levou ao desenvolvimento de ferramentas que tornam possível produzir, rápida e automaticamente, modelos capazes de analisar dados maiores e mais complexos, e entregar resultados mais rápidos e precisos, mesmo em grande escala. E ao construir modelos precisos, uma organização tem mais chances de identificar oportunidades lucrativas, ou de evitar riscos desconhecidos.</p>
<p>Com o advento do <em>Deep Learning</em>, que é um tipo de <em>Machine Learning</em>, conseguimos reproduzir o mecanismo de aprendizagem e reconhecimento de um neurônio humano em linhas de código.</p>
<p>Técnicas de <em>deep learning</em> têm melhorado significativamente a capacidade dos computadores de reconhecer, classificar, detectar e descrever algum tipo de informação. Dessa forma ele tem sido usado para classificação de imagens, reconhecimento de fala, detecção de objetos e descrição de conteúdo, por exemplo.</p>
<h3 id=primeira-abordagem>Primeira Abordagem</h3>
<p>Inicialmente, o grupo recorreu a literatura e à internet para encontrar referências a cerca do tema. Um trabalho anterior do CiDAMO disponível no <a href=https://github.com/Egmara/Machine-Learning-Projeto-UFPR-Reconhecimento-de-algarismos title="Reconhecimento de Caracteres Matemáticos">GitHub</a><sup>[1]</sup>, dos alunos João Fassina, Egmara Antunes e Renan Domingues, realizava o reconhecimento de dígitos matemáticos (0 a 9). Foi o primeiro passo tomado pela nossa equipe, antes de estender a solução para os demais caracteres matemáticos.</p>
<p>Na sequência, outro estudo local guiou o trabalho do nosso grupo. O graduando em Matemática, Carlos Henrique Venturi Ronchi, orientado pelo Prof. Abel Siqueira, coordenador do CiDAMO, realizou um estudo matemático a respeito do <a href="https://abelsiqueira.github.io/assets/alunos/2017/carlos-ronchi.pdf#page=40&zoom=100,112,66">reconhecimento de caracteres</a><sup>[2]</sup>, o que forneceu ainda mais insumos para a solução do problema. Por fim, usamos um curso de <em>Machine Learning</em> e <em>Deep Learning</em> no <em>TensorFlow</em> para nos auxiliar na montagem do nosso modelo.</p>
<p>Estudando o problema, identificamos que a solução para este seria um modelo de classificação de classes. Em uma primeira análise, consideramos 4 modelos de classificação diferentes para utilizar no nosso problema. Entre eles, estão: <em>Artifitial Neural Networks</em> (ANN), <em>Random Forest</em>, <em>Support Vector Classification</em> (SCV) e <em>Convolutional Neural Networks</em> (CNN). Após testar um primeiro modelo montado por nós e levando em consideração alguns pontos do trabalho anterior do CiDAMO, decidimos escolher o modelo de Redes Neurais Convolucionais (CNN) para dar continuidade no nosso trabalho, pois este modelo mostrou uma performance melhor, com maior acurácia, se comparado com os outros modelos.</p>
<h2 id=redes-neurais-convolucionais-cnn>Redes Neurais Convolucionais (CNN)</h2>
<p>As redes neurais convolucionais foram desenvolvidas tomando como base o córtex visual de animais. Nela, assim como no córtex, temos várias regiões denominadas de campos receptivos e são formadas por subconjuntos selecionados do vetor de características a ser analisado. A estrutura das redes concolucionais possui 3 objetivos principais: Extração de características, mapeamento de características e subamostragem. A figura abaixo exemplifica o processo de uma rede convolucional.</p>
<figure><img src=https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png><figcaption>
<h4>Ilustração do processo de uma rede convolucional. Fonte: Wikipedia [3]</h4>
</figcaption>
</figure>
<p>Cada campo receptível, na <a href=https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-1-convolution-operation>camada de convolução</a><sup>[4]</sup>, é responsável por extrair características (<em>features</em>) locais da imagem. A extração dessas características locais faz com que a posição exata de cada característica seja irrelevante, desde que sua posição em relação às características vizinhas seja mantida. Por exemplo, no reconhecimento facial, não importa onde os olhos estejam posicionados, desde que eles estejam próximos e na posição correta em relação à orelha, nariz e boca. Desta forma, podemos analisar a imagem localmente e não globalmente, sendo possível descartar ruídos que estejam em volta do rosto.</p>
<p>Seguindo, cada camada computacional da rede é composta por diversos mapas de características (<em>feature maps</em>), que são regiões onde os neurônios compartilham os mesmos pesos sinápticos (<em>kernels</em>), que dão robustez ao modelo, fazendo com que ele seja capaz de lidar com variações de rotação, translação e distorção da imagem, reduzindo drasticamente o número de parâmetros a serem otimizados.</p>
<p>Após cada camada de convolução, são coletadas amostras de cada mapa de característica e reunidas em subamostragens (<em>subsampling</em> ou <em>pooling</em>). Uma camada de <a href=http://deeplearningbook.com.br/camadas-de-pooling-em-redes-neurais-convolucionais/><em>pooling</em></a><sup>[5]</sup> recebe cada saída do mapa de características da camada convolucional e prepara um mapa de características condensadas. O processo de <a href=https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-2-max-pooling/><em>max-pooling</em></a><sup>[6]</sup> é uma forma de a rede encontrar um determinado recurso em qualquer lugar de uma região da imagem. Em seguida, elimina a informação posicional exata, importando somente sua localização aproximada em relação a outros recursos. O processo é repetido pelo número de camadas escolhidas para o modelo.</p>
<p>Feito isso, é empregado o processo de <a href=https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening><em>flatenning</em></a><sup>[7]</sup>, que basicamente pega as camadas de pooling da última subamostragem e as transforma em um único longo vetor que será usado como input para a rede neural artificial.</p>
<figure><img src=https://i.postimg.cc/cHqvbHxg/2-flatenning.png><figcaption>
<h4>Ilustração do processo de Flattening. Fonte: Super Data Science [7]</h4>
</figcaption>
</figure>
<p>Por fim, nosso vetor pode ser usado na <a href=https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-4-full-connection>rede neural artificial</a><sup>[8]</sup>. O objetivo dessa rede é combinar exaustivamente as características em uma variedade de atributos para tornar a rede convolucional mais capaz de classificar as imagens.</p>
<p>A rede neural artificial então faz sua previsão da classe baseando-se nos dados do vetor e os pesos sinápticos. A classe que apresentar as maiores probabilidades de possuir as características do nosso vetor, mantendo também a posição relativa entre as características, será a escolhida pelo modelo. Abaixo temos um exemplo de rede neural para exemplificar.</p>
<figure><img src=../img/reconhecimento-caracteres/neural-network.png><figcaption>
<h4>Exemplo de uma Rede Neural Artificial usada para estimar as probabilidades de cada classe. Fonte: TEXample [9]</h4>
</figcaption>
</figure>
<h2 id=obtenção-do-banco-de-dados>Obtenção do Banco de Dados</h2>
<p>Para rodar nosso modelo, encontramos 3 <em>datasets</em> diferentes que poderiam ser usados na solução do problema. O <em>dataset</em> <a href=https://www.kaggle.com/xainano/handwrittenmathsymbols><em>“Hand written math symbols”</em></a><sup>[10]</sup> é composto de mais de 100.000 imagens de caracteres matemáticos manuscritos de 45x45 <em>pixels</em>. Além dele, achamos o <em>dataset</em> <a href=https://www.kaggle.com/guru001/hasyv2#symbols.csv><em>“HASYv2”</em></a><sup>[11]</sup> que consiste em 150.000 símbolos manuscritos, divididos em 369 classes e disponibilizados em imagens de 32x32 <em>pixels</em>. Por fim, encontramos o <em>dataset</em> <a href=http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/><em>“Chars74k”</em></a><sup>[12]</sup> que consiste de 74.000 imagens de símbolos matemáticos, com 128x128 <em>pixels</em> de dimensão, tanto manuscritas, quanto segmentadas de cenários naturais e escritas a partir de fontes do computador.
Tivemos alguns problemas antes de trabalhar com o <em>dataset</em>, como é de se esperar para um projeto de <em>Machine Learning</em>, pois haviam diversas imagens borradas, erradas ou até mesmo inapropriadas. Abaixo podemos ver alguns dos exemplos da pasta do símbolo “não existe” de imagens que tiveram que ser descartadas; na segunda imagem, o símbolo em si não está errado (existe unicamente), porém estava tabelado de maneira errada.</p>
<figure><img src=https://i.postimg.cc/8P15qLTV/4-img-errada.png><figcaption>
<h4>Exemplos de caracteres descartados</h4>
</figcaption>
</figure>
<p>Após um extensivo trabalho de seleção, reunimos um conjunto de dados com caracteres manuscritos condizentes com a realidade. Após um estudo sobre o tamanho da amostra necessário para não afetar a acurácia do modelo, chegamos ao valor aproximado de 250 imagens para cada classe selecionada, nos deixando com um conjunto de 30 classes e perto de 7.000 imagens de 28x28 <em>pixels</em>. Abaixo podemos ver uma ilustração da quantidade de imagens para cada classe selecionada.</p>
<figure><img src=https://i.postimg.cc/fb0TxKfY/5-classes.png><figcaption>
<h4>Número de imagens no dataset para cada classe</h4>
</figcaption>
</figure>
<h2 id=modelo>Modelo</h2>
<p>Antes de passar pela rede convolucional, as imagens precisam passar por algumas fases de processamento, sendo utilizada a biblioteca <em>open source</em> <a href=https://docs.opencv.org/2.4/modules/imgproc/doc/imgproc.html><em>OpenCV</em></a><sup>[13]</sup> de visão computacional e aprendizade de máquinas. Primeiramente, a imagem é <a href=https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#resize>redimensionada</a> (<em>Resize</em>) para 28x28 <em>pixels</em>, seguida de uma <a href=https://docs.opencv.org/2.4/modules/imgproc/doc/histograms.html#equalizehist>equalização do histograma</a> (<em>EqualizeHist</em>) na imagem para acentuar detalhes perdidos no redimensionamento. Após, a imagem passa por um processo de <a href=https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html#blur>suavização das linhas</a> (<em>Blur</em>) para finalmente acertar a cor dos <em>pixels</em> estipulando um <a href=https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#adaptivethreshold>limite de intensidade</a> no <em>pixel</em> para classificá-lo binariamente como branco ou preto (<em>AdaptiveThreshold</em>).</p>
<p>Abaixo temos uma ilustração do processo descrito acima para cada <em>dataset</em> diferente (<em>&ldquo;Chars74k&rdquo;</em>, <em>&ldquo;Hand written math symbols&rdquo;</em>, <em>&ldquo;HASYv2&rdquo;</em>), ficando clara a diferença no resultado.</p>
<figure><img src=https://i.postimg.cc/QCqMFdkP/6-img-proc-1.png><figcaption>
<h4>Ilustração das etapas de processamento nas imagens</h4>
</figcaption>
</figure>
<p>Para os símbolos manuscritos, a caligrafia pode influenciar bastante no aprendizado do modelo.</p>
<figure><img src=https://i.postimg.cc/CMC5PcTN/7-img-proc-2.png><figcaption>
<h4>Etapas de processamento para um símbolo manuscrito</h4>
</figcaption>
</figure>
<p>O resultado pode ser afetado por ruídos externos ao símbolo, como podemos ver no exemplo abaixo.</p>
<figure><img src=https://i.postimg.cc/pXqTxyd5/8-img-proc-3.png><figcaption>
<h4>Efeitos de ruídos externos no processamento</h4>
</figcaption>
</figure>
<p>Na primeira camada convolucional, temos 2 conjuntos de 60 <em>feature maps</em> seguidos de um processo de <em>max pooling</em>; já a segunda camada convolucional é composta por 2 conjuntos de 30 <em>feature maps</em> seguidos também de um processo de <em>max pooling</em>. Logo após, ocorre o flattening dos <em>feature maps</em> para ser processado por duas redes neurais densas de 500 e 30 nós respectivamente.</p>
<p>Levnado em consideração o vetor gerado pelo flattening e os pesos sinápticos, o modelo pode então fazer sua previsão.</p>
<figure><img src=https://i.postimg.cc/jjBxSkmG/9-conv.png><figcaption>
<h4>Ilustração das camadas de uma rede convolucional</h4>
</figcaption>
</figure>
<p>Alguns parâmetros precisam ser definidos para nosso modelo:</p>
<ul>
<li>
<p><em>Batch</em>: Número de imagens que vão passar pelo modelo de uma vez; no nosso caso, cada <em>batch</em> continha 32 imagens.</p>
</li>
<li>
<p><em>Epoch</em>: Número de vezes que o modelo irá treinar em cima de todo o <em>dataset</em>; para nosso modelo, escolhemos o valor de 50 épocas.</p>
</li>
<li>
<p><em>Steps per epoch</em>: Número de <em>batches</em> que irão rodar no modelo antes que se verifique a performance deste; definimos o valor de 1500 <em>steps</em>.</p>
</li>
</ul>
<p>Para evitar <em>overfitting</em>, uma vez que o número de épocas foi arbitrário, usamos o API do <em>TensorFlow</em> para <em>python</em>, chamado <em>Keras</em>. Nele, achamos um conjunto de funções denominado <a href=https://keras.io/api/callbacks/><em>Callback</em></a><sup>[14]</sup>, permitindo fazer procedimentos em qualquer ponto do treino.</p>
<p>A funçao <em>EarlyStopping</em>, presente no conjunto <em>Callback</em>, interrompe o treino do modelo antes que haja um <em>overfitting</em>. Ela leva em consideração o valor a ser monitorado (função de perda), a variação no valor e o número de épocas sem melhora no modelo. Como resultado do nosso treino, nosso modelo foi interrompido após 11 épocas.</p>
<p>Feito o treino do modelo, podemos agora avaliar a precisão média para cada classe, dentre outras métricas.</p>
<figure><img src=https://i.postimg.cc/4dk4w9Wq/10-precisao.png><figcaption>
<h4>Precisão média de cada classe</h4>
</figcaption>
</figure>
<h2 id=resultados>Resultados</h2>
<p>Com nosso modelo devidamente treinado e avaliado, podemos agora fazer previsões a partir de uma <em>web-cam</em>, utilizando o módulo <em>cv2</em> da biblioteca <em>OpenCV</em> para se usar em <em>python</em>. O programa lê a filmagem da <em>web-cam</em> como se fossem diversas fotos em sequência, prevendo a classe da imagem e disponibilizando a probabilidade de acerto da mesma.</p>
<figure><img src=https://i.postimg.cc/90cmHj5B/11-pred.png><figcaption>
<h4>Modelo em funcionamento utilizando uma webcam</h4>
</figcaption>
</figure>
<p>Algumas classes apresentaram dificuldade na hora de prever corretamente o resultado devido à perda de qualidade no processo de tratamento das imagens; abaixo encontramos alguns casos em que o modelo não conseguiu reconhecer a classe.</p>
<figure><img src=https://i.postimg.cc/4d6f0xMd/12-ruim.png><figcaption>
<h4>Classes que apresentaram dificuldade em ser reconhecida</h4>
</figcaption>
</figure>
<p>Como mencionado anteriormente, nosso modelo interrompeu o treino em 11 épocas; plotando o gráfico da ácuracia, temos a linha azul para o conjunto de treino e a linha laranja para o conjunto de teste. A partir desse ponto, a acurácia começou a cair significativamente, forçando o comando <em>Callback</em>.</p>
<figure><img src=https://i.postimg.cc/52ytt1H7/13-acuracia.png><figcaption>
<h4>Gráfico da acurácia no modelo de treino e de teste</h4>
</figcaption>
</figure>
<p>Agora avaliando a função de perda do modelo, podemos ver que na quantidade de épocas ótima, temos o menor valor para a função de perda; a partir desse ponto, a função voltava a crescer.</p>
<figure><img src=https://i.postimg.cc/JzFzDgZ1/14-perda.png><figcaption>
<h4>Gráfico da perda no modelo de treino e de teste</h4>
</figcaption>
</figure>
<h3 id=conclusão-e-pontos-a-melhorar>Conclusão e Pontos a Melhorar</h3>
<p>Neste trabalho, abordamos o assunto de reconhecimento de caracteres matemáticos através de modelos de <em>Machine Learning</em>, mais concretamente utilizando-se da técnica de redes neurais convolucionais. Conseguimos visualizar como esse processo funciona por trás das linhas de código e como o modelo toma suas decisões, além de vislumbrar as diversas aplicações deste método para problemas distintos.</p>
<p>Mesmo conseguindo cumprir com o objetivo do problema, ainda restam pontos de melhoria no projeto, que podem ficar de inspiração para quem queira se aventurar. Nessa seção iremos elucidar alguns deles.</p>
<p>Uma primeira melhoria seria implementar uma caixa de contorno, como aquelas vistas em modelos de carros autônomos ou até mais recente, em modelos de reconhecimento do uso de máscara. Outra melhoria relacionada com esse ponto seria o reconhecimento do posicionamento do caractere, como por exemplo uma expressão dentro de raiz quadrada, algum índice subscrito ou de potência.</p>
<p>Com relação ao dimensionamento das imagens, tentamos rodar o modelo com imagens de dimensão maior que os 28x28 <em>pixels</em> escolhidos, porém isso afetou muito nosso resultado; um aumento na dimensão cria muito ruído, que acaba afetando a acurácia do modelo. Outro ponto seria melhorar o tratamento das imagens; melhorando a sensibilidade do filtro, o modelo poderia dar mais destaque ao número em si e relevar mais os ruídos. Uma melhora no tratamento das imagens pode contribuir com o problema encontrado no aumento da dimensão das imagens.</p>
<p>Por fim, a respeito do modelo, percebemos dois pontos passíveis de melhoria. Uma rede convolucional mais complexa e com mais camadas poderia solucionar o problema de ruído que enfrentamos, dando mais destaque ao número e relevando sombras e ruídos. Outro ponto do modelo que também poderia ser otimizado é o número de parâmetros, que também deixaria o modelo mais assertivo e confiável. O contraponto que isso gera é a relação Complexidade x Poder Computacional. É necessário um estudo mais a fundo de como o aumento na complexidade do modelo poderia afetar o consumo de poder computacional, gerando maiores gastos.</p>
<h2 id=referências>Referências</h2>
<p>[1] MACHINE-Learning-Projeto-UFPR-Reconhecimento-de-algarismos. <b>GitHub</b>. Disponível em: <a href=https://github.com/Egmara/Machine-Learning-Projeto-UFPR-Reconhecimento-de-algarismos>https://github.com/Egmara/Machine-Learning-Projeto-UFPR-Reconhecimento-de-algarismos</a>. Acesso em 12 de abril de 2020</p>
<p>[2] ESTUDO matemático do reconhecimento de caracteres. <b>GitHub</b>. Disponível em: <a href="https://abelsiqueira.github.io/assets/alunos/2017/carlos-ronchi.pdf#page=40&zoom=100,112,66">https://abelsiqueira.github.io/assets/alunos/2017/carlos-ronchi.pdf#page=40&zoom=100,112,66</a>. Acesso em 12 de abril de 2020</p>
<p>[3] FILE: Typical cnn.png. <b>Wikipedia</b>. Disponível em: <a href=https://en.wikipedia.org/wiki/File:Typical_cnn.png>https://en.wikipedia.org/wiki/File:Typical_cnn.png</a>. Acesso em 20 de maio de 2020.</p>
<p>[4] CONVOLUTIONAL Neural Networks (CNN): Step 1- Convolution Operation. <b>Super Data Science</b>. Disponível em: <a href=https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-1-convolution-operation>https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-1-convolution-operation</a>. Acesso em: 12 de maio de 2020.</p>
<p>[5] CAPÍTULO 43 – Camadas de Pooling em Redes Neurais Convolucionais. <b>Deep Learning Book</b>. Disponível em: <a href=http://deeplearningbook.com.br/camadas-de-pooling-em-redes-neurais-convolucionais/>http://deeplearningbook.com.br/camadas-de-pooling-em-redes-neurais-convolucionais/</a>. Acesso em: 12 de maio de 2020.</p>
<p>[6] CONVOLUTIONAL Neural Networks (CNN): Step 2 - Max Pooling. <b>Super Data Science</b>. Disponível em: <a href=https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-2-max-pooling/>https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-2-max-pooling/</a>. Acesso em: 12 de maio de 2020.</p>
<p>[7] CONVOLUTIONAL Neural Networks (CNN): Step 3 - Flattening. <b>Super Data Science</b>. Disponível em: <a href=https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening>https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening</a>. Acesso em: 12 de maio de 2020.</p>
<p>[8] CONVOLUTIONAL Neural Networks (CNN): Step 4 - Full Connection. <b>Super Data Science</b>. Disponível em: <a href=https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-4-full-connection>https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-4-full-connection</a>. Acesso em: 12 de maio de 2020.</p>
<p>[9] EXAMPLE: Neural network. <b>TEXample</b>. Disponível em: <a href=http://www.texample.net/tikz/examples/neural-network/>http://www.texample.net/tikz/examples/neural-network/</a>. Acesso em 20 de maio de 2020.</p>
<p>[10] HANDWRITTEN math symbols dataset. <b>Kaggle</b>. Disponível em: <a href=https://www.kaggle.com/xainano/handwrittenmathsymbols>https://www.kaggle.com/xainano/handwrittenmathsymbols</a>. Acesso em: 15 de abril de 2020.</p>
<p>[11] HASYV2: HandWritten Alphanumeric chars - Numbers, Letters, Mathematical & Scientific Symbols. <b>Kaggle</b>. Disponível em: <a href=https://www.kaggle.com/guru001/hasyv2#symbols.csv>https://www.kaggle.com/guru001/hasyv2#symbols.csv</a>. Acesso em: 15 de abril de 2020.</p>
<p>[12] THE Chars74K dataset. <b>EE Surrey</b>. Disponível em: <a href=http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/>http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/</a>. Acesso em: 15 de abril de 2020.</p>
<p>[13] IMGPROC. Image Processing. <b>OpenCV</b>. Disponível em: <a href=https://docs.opencv.org/2.4/modules/imgproc/doc/imgproc.html>https://docs.opencv.org/2.4/modules/imgproc/doc/imgproc.html</a>. Acesso em 20 de maio de 2020.</p>
<p>[14] CALLBACKS API. <b>Keras</b>. Disponível em: <a href=https://keras.io/api/callbacks/>https://keras.io/api/callbacks/</a>. Acesso em 20 de maio de 2020.</p>
</div>
</div>
</div>
<div class=col-md-4>
<aside class=sidebar><div class="widget widget-latest-post">
<h4 class=widget-title>Últimos Posts</h4>
<div class=media>
<a class=pull-left href=/blog/2021-05-17-postmortem-da-2a-cidweek/>
<img class=media-object src=/images/blog/PostMortem.jpg alt="Postmortem da 2ª CiDWeek">
</a>
<div class=media-body>
<h4 class=media-heading><a href=/blog/2021-05-17-postmortem-da-2a-cidweek/>Postmortem da 2ª CiDWeek</a></h4>
<p>Olá novamente. Espero que você tenha gostado da 2ª …</p>
</div>
</div>
<div class=media>
<a class=pull-left href=/blog/2021-03-01-ii-cidweek/>
<img class=media-object src=/images/eventos/CiDWeek-02.jpg alt="II CiDWeek">
</a>
<div class=media-body>
<h4 class=media-heading><a href=/blog/2021-03-01-ii-cidweek/>II CiDWeek</a></h4>
<p>Entre os dias 26 e 30 de abril o CiDAMO irá …</p>
</div>
</div>
<div class=media>
<a class=pull-left href=/blog/2020-09-20-hacktoberfest-2020/>
<img class=media-object src=/images/blog/hacktoberfest-2020.jpg alt="Hacktoberfest 2020">
</a>
<div class=media-body>
<h4 class=media-heading><a href=/blog/2020-09-20-hacktoberfest-2020/>Hacktoberfest 2020</a></h4>
<p>Você conhece o Hacktoberfest?
Vídeo apresentando …</p>
</div>
</div>
<div class=media>
<a class=pull-left href=/blog/2020-07-27-reviews-de-restaurantes/>
<img class=media-object src=/images/blog/review-restaurantes/capa.jpg alt="Análise de sentimentos em reviews de restaurantes">
</a>
<div class=media-body>
<h4 class=media-heading><a href=/blog/2020-07-27-reviews-de-restaurantes/>Análise de sentimentos em reviews de restaurantes</a></h4>
<p>O presente projeto busca usar técnicas de machine …</p>
</div>
</div>
</div>
<div class="widget widget-category">
<h4 class=widget-title>Categorias</h4>
<ul class=widget-category-list>
<li><a href=/categories/eventos/>Eventos</a></li>
<li><a href=/categories/novidades/>Novidades</a></li>
<li><a href=/categories/projetos/>Projetos</a></li>
</ul>
</div>
<div class="widget widget-tag">
<h4 class=widget-title>Tags</h4>
<ul class=widget-tag-list>
<li><a href=/tags/cidweek/>CiDWeek</a></li>
<li><a href=/tags/classifica%C3%A7%C3%A3o/>Classificação</a></li>
<li><a href=/tags/hacktoberfest/>Hacktoberfest</a></li>
<li><a href=/tags/postmortem/>PostMortem</a></li>
<li><a href=/tags/previs%C3%A3o/>Previsão</a></li>
<li><a href=/tags/regress%C3%A3o/>Regressão</a></li>
<li><a href=/tags/sele%C3%A7%C3%A3o/>Seleção</a></li>
<li><a href=/tags/site/>Site</a></li>
</ul>
</div>
</aside>
</div>
</div>
</div>
</section>
<footer class=footer>
<div class=container>
<div class=row>
<div class=col-md-12>
<div class=footer-menu>
<ul class=social-icons>
<li><a href=mailto:grupo.cidamo@gmail.com><i class="fa fa-envelope"></i></a></li>
<li><a href=https://www.linkedin.com/company/grupo-cidamo><i class="fa fa-linkedin"></i></a></li>
<li><a href=https://www.twitter.com/grupo_cidamo><i class="fa fa-twitter"></i></a></li>
<li><a href=https://www.instagram.com/grupo.cidamo><i class="fa fa-instagram"></i></a></li>
<li><a href=https://www.youtube.com/GrupoCiDAMO><i class="fa fa-youtube"></i></a></li>
<li><a href=https://github.com/CiDAMO><i class="fa fa-github"></i></a></li>
</ul>
<br>
<ul>
<li><a href=/sobre>Sobre</a></li>
<li><a href=/equipe>Equipe</a></li>
<li><a href=/eventos>Eventos</a></li>
<li><a href=/blog>Blog</a></li>
</ul>
</div>
<p class=copyright>Copyright © 2021 Abel Soares Siqueira</p>
</div>
</div>
</div>
</footer>
<script src=/plugins/jquery/jquery.min.js></script>
<script src=/plugins/bootstrap/js/bootstrap.min.js></script>
<script src=/plugins/slick/slick.min.js></script>
<script src=/plugins/magnific-popup/magnific-popup.min.js></script>
<script src=/plugins/shuffle/shuffle.min.js></script>
<script src=/plugins/google-map/gmap.js defer></script>
<script src=https://kit.fontawesome.com/d17d5e5245.js></script>
<script src=/js/bundled.min.js></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script type=text/javascript async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$']],processEscapes:!0,processEnvironments:!0,skipTags:['script','noscript','style','textarea','pre'],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var b=MathJax.Hub.getAllJax(),a;for(a=0;a<b.length;a+=1)b[a].SourceElement().parentNode.className+=' has-jax'}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/js-cookie/2.2.1/js.cookie.min.js></script>
<div id=js-cookie-box class="cookie-box cookie-box-hide">
This site uses cookies. By continuing to use this website, you agree to their use. <span id=js-cookie-button class="btn btn-main btn-solid-border">I Accept</span>
</div>
<script>(function(c){const a=document.getElementById('js-cookie-box'),b=document.getElementById('js-cookie-button');Cookies.get('cookie-box')||(a.classList.remove('cookie-box-hide'),b.onclick=function(){Cookies.set('cookie-box',!0,{expires:2}),a.classList.add('cookie-box-hide')})})(jQuery)</script>
<style>.cookie-box{position:fixed;left:0;right:0;bottom:0;text-align:center;z-index:9999;padding:1rem 2rem;background:#474747;transition:all .75s cubic-bezier(.19,1,.22,1);color:#fdfdfd}.cookie-box-hide{display:none}</style>
</body>
</html>