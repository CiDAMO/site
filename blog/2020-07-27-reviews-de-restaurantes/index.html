<!doctype html><html lang=pt-br><head><meta charset=utf-8><title>Análise de sentimentos em reviews de restaurantes</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="O presente projeto busca usar técnicas de machine learning para classificar os reviews de restaurantes em reviews positivos ou negativos, sendo um problema estudado no campo de análise de sentimentos."><meta name=author content="Themefisher"><meta name=generator content="Hugo 0.101.0"><meta property="og:image" content="https://cidamo.com.br/site/images/blog/review-restaurantes/capa.jpg"><meta name=twitter:image content="https://cidamo.com.br/site/images/blog/review-restaurantes/capa.jpg"><meta name=twitter:card content="summary"><meta property="og:image:width" content="1080"><meta property="og:image:height" content="1080"><meta property="og:image:type" content="image/jpeg"><meta name=twitter:title content="Análise de sentimentos em reviews de restaurantes"><meta name=twitter:description content="O presente projeto busca usar técnicas de machine learning para classificar os reviews de restaurantes em reviews positivos ou negativos, sendo um problema estudado no campo de análise de sentimentos."><meta property="og:title" content="Análise de sentimentos em reviews de restaurantes"><meta property="og:description" content="O presente projeto busca usar técnicas de machine learning para classificar os reviews de restaurantes em reviews positivos ou negativos, sendo um problema estudado no campo de análise de sentimentos."><meta property="og:type" content="article"><meta property="og:url" content="https://cidamo.com.br/site/blog/2020-07-27-reviews-de-restaurantes/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2020-07-27T00:00:00+00:00"><meta property="article:modified_time" content="2020-07-27T00:00:00+00:00"><link rel=stylesheet href=/site/plugins/bootstrap/css/bootstrap.min.css media=screen><link rel=stylesheet href=/site/plugins/ionicons/css/ionicons.min.css><link rel=stylesheet href=/site/plugins/magnific-popup/magnific-popup.min.css><link rel=stylesheet href=/site/plugins/slick/slick.css><link rel=stylesheet href=/site/scss/bundled.min.css media=screen><link rel="shortcut icon" href=/site/images/favicon.png type=image/x-icon><link rel=icon href=/site/images/favicon.png type=image/x-icon></head><body><div class=preloader></div><header class=navigation><div class=container-fluid><div class=row><div class=col-md-12><nav class=navbar><div class=navbar-header><button type=button class="navbar-toggle collapsed" data-toggle=collapse data-target=#navigation>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button>
<a class=navbar-brand href=/><img src=/site/images/logo.png alt=CiDAMO width=150px class=img-responsive></a></div><div class="collapse navbar-collapse" id=navigation><ul class="nav navbar-nav navbar-right"><li><a href=/site/>Home</a></li><li><a href=/site/sobre/>Sobre</a></li><li><a href=/site/equipe/>Equipe</a></li><li><a href=/site/eventos/>Eventos</a></li><li><a href=/site/blog/ class=current-parent>Blog</a></li></ul></div></nav></div></div></div></header><section class="page-title bg-2" style=background-image:url(/site/images/blog/review-restaurantes/capa.jpg)><div class=container><div class=row><div class=col-md-12><div class=block><h1>Análise de sentimentos em reviews de restaurantes</h1><p></p></div></div></div></div></section><section class=page-wrapper><div class=container><div class=row><div class=col-md-8><div class="post post-single"><h2 class=post-title>Análise de sentimentos em reviews de restaurantes</h2><div class=post-meta><ul><li><i class=ion-calendar></i> July 27, 2020</li><li><i class=ion-android-people></i>
<a class=text-primary href=/site/author/dennis-gon%C3%A7alves-lemes>Dennis Gonçalves Lemes</a>, <a class=text-primary href=/site/author/victor-gabriel-souza-barbosa>Victor Gabriel Souza Barbosa</a>, <a class=text-primary href=/site/author/vin%C3%ADcyus-ara%C3%BAjo-brasil>Vinícyus Araújo Brasil</a></li><li><i class=ion-pricetags></i>
<a href=/site/tags/classifica%c3%a7%c3%a3o>Classificação</a></li></ul></div><div class=post-thumb><img class=img-responsive src=/site/images/blog/review-restaurantes/capa.jpg alt="Análise de sentimentos em reviews de restaurantes"></div><div class="post-content post-excerpt"><p>O presente projeto busca usar técnicas de machine learning para classificar os reviews de restaurantes em reviews positivos ou negativos, sendo um problema estudado no campo de análise de sentimentos.</p><p>A tarefa é clássica no campo do processamento de linguagem natural (PLN) como mostra Kharde (2016). Os modelos de Machine Learning tem tido resultados melhores que os modelos baseados no léxico, o que mostra um novo padrão em PLN. Um exemplo é o Google, que desenvolve e usa modelos em seus produtos (como o BERT no Google Search).</p><p>Ilustraremos o post com partes dos códigos, sendo que os scripts completos podem ser encontrados no nosso <strong>Github</strong>.</p><h2 id=base-de-dados>Base de dados</h2><p>Usaremos os reviews do site <strong>Trip Advisor</strong>, visto que é um dos maiores sites do ramo e possui vasto número de avaliações. A coleta dos dados foi feita via web scraping, dado que o site não fornece uma API para tal finalidade.</p><p>Nosso Web Scraping tem como base um código disponibilizado por uma usuária do Github e adaptamos para extrair os dados para nosso modelo. O código pode ser obtido <a href=https://github.com/susanli2016/NLP-with-Python/blob/master/Web%20scraping%20Hilton%20Hawaiian%20Village%20TripAdvisor%20Reviews.py>aqui</a>. Ao adaptarmos, nosso objetivo era obter todos os reviews de cada restaurante selecionado previamente e transformá-los em arquivos .csv, a princípio tínhamos como objetivo restaurantes de todo o Brasil, porém devido a quantidade massiva de dados, nosso dataset contém restaurantes apenas da cidade de Curitiba. Os restaurantes escolhidos foram os restaurantes da cidade que continham mais reviews, ou seja, não houve discriminação no que tange a tipos de restaurantes ou tipo de comida, por exemplo. Os links dos restaurantes foram coletados manualmente e colocados em um arquivo txt e geramos o arquivo csv com os reviews com o script gera_csv. O csv tinha como formato 3 colunas, sendo elas:</p><pre><code>ID, Nota de Review (1-5), Texto de Review (Comentário feito pelo usuário)
</code></pre><p>Os reviews foram separados da seguinte forma: reviews positivos tem nota 4 ou 5 e reviews negativos tem nota 1, 2 ou 3. Então, no csv, temos uma variável binária: o review positivo tem valor igual à 1 e o review negativo tem valor igual à 0. Tal forma de classificar os dados foi feita por dois motivos principais. O primeiro é a subjetividade de cada pessoa no que tange às notas, ou seja, pessoas diferentes tem ideias diferentes do que é um restaurante nota 3, por exemplo. Dividir o banco de dados em reviews positivos ou negativos elimina esta subjetividade.</p><p>Outro motivo é que o Trip Advisor deleta restaurantes com muitas reviews negativas do seu site, o que resulta em muito mais reviews positivas do que negativas presentes. Devido a isso, foram coletadas por volta de 144 mil reviews no total, dentro delas 16 mil negativas.Para que o dataset fique equilibrado, selecionamos aleatoriamente 16 mil reviews positivos, criando uma base de dados com 32 mil reviews.</p><p>Com isso, possuíamos os dados para serem trabalhados. O código para esta parte é o arquivo gera_csv_final no Github.</p><h2 id=modelos>Modelos</h2><p>Os modelos que usaremos se baseiam em Kharde(2016). Usaremos modelos que são clássicos de tarefas de aprendizado supervisionado, sendo eles:</p><ul><li>Regressão Logística;</li><li>SVM (na sua &ldquo;versão&rdquo; polinomial);</li><li>Random Forest;</li></ul><p>O outro modelo que usaremos é o BERT, apresentado em Devlin et al (2018), que funciona de uma forma um pouco diferente dos outros modelos acima apresentados. O modelo é uma rede neural pré-treinada com <em>Self-Supervised Learning</em> em textos (como o Wikipedia, por exemplo) que utiliza técnicas como o <em>Attention</em> e <em>Fine-Tuning</em>, entre outras. Os autores mostram que tal tipo de arquitetura atingiu resultados sublimes em várias tarefas clássicas de PLN. Visto isso, adicionamos o BERT ao projeto visando compará-lo com os modelos clássicos. A implementação foi baseada no código de <a href=https://github.com/chriskhanhtran/bert-for-sentiment-analysis>Kahnhtran</a>.</p><h2 id=vetorização>Vetorização</h2><p>Para que os modelos que usaremos possam entender a linguagem humana, devemos transformar as palavras em vetores numéricos. Há três principais formas de se fazer isso: a vetorização TFIDF, Word2Vec e o Dynamic Word Embedding.</p><p>A primeira forma usa o método TF-IDF (<em>Term Frequency - Inverse Document Frequency</em>) para transformar as palavras em vetores. Usaremos este método de vetorização nos modelos de Regressão Logística, no Random Forest e no SVM. Usaremos, para tal, a função tfidfVectorizer() do <strong>scikit-learn</strong>.</p><pre><code>t_vector = TfidfVectorizer()
t_vector.fit(data_clean['review_body'])
train_X = t_vector.transform(X_train['review_body'])
test_X = t_vector.transform(X_test['review_body'])
</code></pre><p>Já o Word2Vec é uma forma de vetorização de palavras de forma que, palavras que tem significados próximos sejam representadas por vetores que tem o ângulo perto de zero. Tal ângulo é medido pela similaridade do cosseno como representado na figura abaixo.</p><figure><img src=/images/blog/review-restaurantes/panda.png><figcaption><h4>Figura 1: ilustração do método da similaridade do cosseno, usado pelo Word2Vec (Karani, 2018)</h4></figcaption></figure><p>O outro método de vetorização, o Dynamic Word Embedding, é similar ao Word2vec mas lida com o problema de palavras com múltiplos significados, criando um vetor novo (com <em>features</em> adequadas) para cada instância da palavra. Há um rede neural treinada em milhões de textos, onde a refinaremos para o nosso problema, treinando ela novamente a fim de ajustar o modelo pré-treinado. Este método é a forma que o modelo BERT que usaremos trata as palavras.</p><h2 id=aplicação-dos-modelos>Aplicação dos modelos</h2><p>Como nosso objetivo a prior se trata de mostrarmos como o <strong>BERT</strong> pode ser extremamente eficiente no nosso projeto, usamos alguns outros modelos para que sua eficiência seja medida.
Todo os modelos usados estão presentes na biblioteca do <strong>scikit-learn</strong>, os modelos utilizados são:</p><ul><li>Regressão Logística;</li><li>Random Forest;</li><li>Support Vector Machine (SVM);</li><li>BERT;</li></ul><p>Um trecho de código aplicando a Regressão Logística como exemplo:</p><pre><code>clf = LogisticRegression()
clf.fit(x_train, y_train)
log_pred = clf.predict(x_test)
</code></pre><p>A implementação do BERT foi baseada no código do <a href=https://github.com/chriskhanhtran/bert-for-sentiment-analysis>Kahnhtran</a>. O BERT, por sua vez tem uma diferença em sua aplicação, como podemos mostrar em um exemplo:</p><pre><code>exemplos_inputs, exemplos_masks  = preprocessing_for_bert(review_exemplo)
exemplo_data = TensorDataset(exemplos_inputs, exemplo_masks)
exemplo_dataloader = DataLoader(exemplo_data, batach_size=batch_size)
</code></pre><p><em>Essa parte pode ser definida como uma &ldquo;preparação dos dados&rdquo;, que antecipa a predição do <strong>BERT</strong></em>.</p><pre><code>probs = bert_predict(bert_classifier, exemplo_dataloader)
</code></pre><p><em>Esse trecho efetivamente realiza a predição dos dados.</em></p><p>Para calcularmos, por exemplo, a acurácia de nosso modelo usamos algo como:</p><pre><code>accuracy_score(log_pred, y_test)
</code></pre><h2 id=resultados>Resultados</h2><p>Enfim, utilizamos a métrica da acurácia e algumas outras para testarmos o potencial do nosso modelo, entre elas estão <strong>acurácia, precisão, recall, escore f1 e a AUC (área sob a curva)</strong>, feito isso criamos uma tabela para comparação intuitiva de &ldquo;desempenho&rdquo;.</p><table><thead><tr><th></th><th style=text-align:center>Reg. Logística</th><th style=text-align:center>Random Forest</th><th style=text-align:center>SVM (Polinomial)</th><th style=text-align:center>BERT</th></tr></thead><tbody><tr><td>Acurácia</td><td style=text-align:center>0.87095</td><td style=text-align:center>0.81844</td><td style=text-align:center>0.88571</td><td style=text-align:center>0.89469</td></tr><tr><td>Precisão</td><td style=text-align:center>0.87435</td><td style=text-align:center>0.82322</td><td style=text-align:center>0.88573</td><td style=text-align:center>0.89910</td></tr><tr><td>Recall</td><td style=text-align:center>0.86800</td><td style=text-align:center>0.81833</td><td style=text-align:center>0.88573</td><td style=text-align:center>0.89148</td></tr><tr><td>F1 Score</td><td style=text-align:center>0.87116</td><td style=text-align:center>0.81833</td><td style=text-align:center>0.88571</td><td style=text-align:center>0.89532</td></tr><tr><td>AUC</td><td style=text-align:center>0.87096</td><td style=text-align:center>0.81847</td><td style=text-align:center>0.88572</td><td style=text-align:center>0.95802</td></tr></tbody></table><h2 id=conclusão>Conclusão</h2><p>Os dois melhores modelos, o BERT e o SVM, conseguem acertar, na média, 89% do total de reviews. É notório que o BERT teve um resultado um pouco melhor no indicador AUC, como mostra a tabela acima, confirmando o que a literatura havia apontado.</p><h2 id=referências>Referências</h2><ul><li>Allamar, J. jalammar.github.io/illustrated-bert/. Acesso em 20/04/2020.</li><li>Carvalho, MH de. <em>Estudo Comparativo dos Métodos de Word Embedding na Análise de Sentimentos.</em> Páginas 20-24. 2018</li><li>Devlin J., Chang M., Lee K., Toutanova K. <em>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.</em> 2018.</li><li>Howard, J. <em>Fine-tuned Language Models for Text Classification</em>. 2018</li><li>Karani, S. <em>Introduction to Word Embedding and Word2Vec</em>. Disponível em <a href=https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa>https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa</a> . Acesso em 13/05/2020. 2018.</li><li>Kharde, V. <em>Sentiment Analysis of Twitter Data: A Survey of Techniques</em>. 2016</li><li>Nayak, P. <em><a href=https://www.blog.google/products/search/search-language-understanding-bert/>www.blog.google/products/search/search-language-understanding-bert/</a></em>. 2019. Acesso em 05/05/2020.</li><li>Rajaraman, A.; Ullman, J.D. Mining of Massive Datasets. 2011.</li></ul></div></div></div><div class=col-md-4><aside class=sidebar><div class="widget widget-latest-post"><h4 class=widget-title></h4><div class=media><a class=pull-left href=/site/blog/2021-05-17-postmortem-da-2a-cidweek/><img class=media-object src=/site/images/blog/PostMortem.jpg alt="Postmortem da 2ª CiDWeek"></a><div class=media-body><h4 class=media-heading><a href=/site/blog/2021-05-17-postmortem-da-2a-cidweek/>Postmortem da 2ª CiDWeek</a></h4><p>Olá novamente. Espero que você tenha gostado da 2ª …</p></div></div><div class=media><a class=pull-left href=/site/blog/2021-03-01-ii-cidweek/><img class=media-object src=/site/images/eventos/CiDWeek-02.jpg alt="II CiDWeek"></a><div class=media-body><h4 class=media-heading><a href=/site/blog/2021-03-01-ii-cidweek/>II CiDWeek</a></h4><p>Entre os dias 26 e 30 de abril o CiDAMO irá …</p></div></div><div class=media><a class=pull-left href=/site/blog/2020-09-20-hacktoberfest-2020/><img class=media-object src=/site/images/blog/hacktoberfest-2020.jpg alt="Hacktoberfest 2020"></a><div class=media-body><h4 class=media-heading><a href=/site/blog/2020-09-20-hacktoberfest-2020/>Hacktoberfest 2020</a></h4><p>Você conhece o Hacktoberfest?
Vídeo apresentando o …</p></div></div><div class=media><a class=pull-left href=/site/blog/2020-07-27-reviews-de-restaurantes/><img class=media-object src=/site/images/blog/review-restaurantes/capa.jpg alt="Análise de sentimentos em reviews de restaurantes"></a><div class=media-body><h4 class=media-heading><a href=/site/blog/2020-07-27-reviews-de-restaurantes/>Análise de sentimentos em reviews de restaurantes</a></h4><p>O presente projeto busca usar técnicas de machine …</p></div></div></div><div class="widget widget-category"><h4 class=widget-title></h4><ul class=widget-category-list><li><a href=/site/categories/eventos/>Eventos</a></li><li><a href=/site/categories/novidades/>Novidades</a></li><li><a href=/site/categories/projetos/>Projetos</a></li></ul></div><div class="widget widget-tag"><h4 class=widget-title></h4><ul class=widget-tag-list><li><a href=/site/tags/cidweek/>CiDWeek</a></li><li><a href=/site/tags/classifica%C3%A7%C3%A3o/>Classificação</a></li><li><a href=/site/tags/hacktoberfest/>Hacktoberfest</a></li><li><a href=/site/tags/postmortem/>PostMortem</a></li><li><a href=/site/tags/previs%C3%A3o/>Previsão</a></li><li><a href=/site/tags/regress%C3%A3o/>Regressão</a></li><li><a href=/site/tags/sele%C3%A7%C3%A3o/>Seleção</a></li><li><a href=/site/tags/site/>Site</a></li></ul></div></aside></div></div></div></section><footer class=footer><div class=container><div class=row><div class=col-md-12><div class=footer-menu><ul class=social-icons><li><a href=mailto:grupo.cidamo@gmail.com><i class="fa fa-envelope"></i></a></li><li><a href=https://www.linkedin.com/company/grupo-cidamo><i class="fa fa-linkedin"></i></a></li><li><a href=https://www.twitter.com/grupo_cidamo><i class="fa fa-twitter"></i></a></li><li><a href=https://www.instagram.com/grupo.cidamo><i class="fa fa-instagram"></i></a></li><li><a href=https://www.youtube.com/GrupoCiDAMO><i class="fa fa-youtube"></i></a></li><li><a href=https://github.com/CiDAMO><i class="fa fa-github"></i></a></li></ul><br><ul><li><a href=/site/sobre>Sobre</a></li><li><a href=/site/equipe>Equipe</a></li><li><a href=/site/eventos>Eventos</a></li><li><a href=/site/blog>Blog</a></li></ul></div><p class=copyright>Copyright © 2021 Abel Soares Siqueira</p></div></div></div></footer><script src=/site/plugins/jquery/jquery.min.js></script>
<script src=/site/plugins/bootstrap/js/bootstrap.min.js></script>
<script src=/site/plugins/slick/slick.min.js></script>
<script src=/site/plugins/magnific-popup/magnific-popup.min.js></script>
<script src=/site/plugins/shuffle/shuffle.min.js></script>
<script src=/site/plugins/google-map/gmap.js defer></script>
<script src=https://kit.fontawesome.com/d17d5e5245.js></script>
<script src=/site/js/bundled.min.js></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script type=text/javascript async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script><script src=https://cdnjs.cloudflare.com/ajax/libs/js-cookie/2.2.1/js.cookie.min.js></script><div id=js-cookie-box class="cookie-box cookie-box-hide">This site uses cookies. By continuing to use this website, you agree to their use. <span id=js-cookie-button class="btn btn-main btn-solid-border">I Accept</span></div><script>(function(){const t=document.getElementById("js-cookie-box"),n=document.getElementById("js-cookie-button");Cookies.get("cookie-box")||(t.classList.remove("cookie-box-hide"),n.onclick=function(){Cookies.set("cookie-box",!0,{expires:2}),t.classList.add("cookie-box-hide")})})(jQuery)</script><style>.cookie-box{position:fixed;left:0;right:0;bottom:0;text-align:center;z-index:9999;padding:1rem 2rem;background:#474747;transition:all .75s cubic-bezier(.19,1,.22,1);color:#fdfdfd}.cookie-box-hide{display:none}</style></body></html>